<h1 id="torch">torch</h1>
<pre class="highlight python"><code><span class="c"># load torch with</span>
<span class="kn">import</span> <span class="nn">torch</span>
</code></pre>
<pre class="highlight python"><code><span class="c"># load the CUDA features of torch with</span>
<span class="kn">import</span> <span class="nn">torch.cuda</span>
</code></pre>

<p><strong>torch</strong> is the main package where data structures for multi-dimensional
tensors and mathematical operations over these are defined.
Additionally, it provides many utilities for efficient serializing of
Tensors and arbitrary types, and other useful utilities.</p>

<p>It has a CUDA counterpart, that enables you to run your tensor computations
on an NVIDIA GPU with compute capability &gt;= 2.0.</p>

<h2 id="multi-core">Multi-core</h2>

<h3 id="torch-get_num_threads">torch.get_num_threads()</h3>

<p>Gets the number of OpenMP threads that will be used for parallelizing CPU operations</p>

<h3 id="torch-set_num_threads-n">torch.set_num_threads(n)</h3>

<p>Sets the number of OpenMP threads to use for parallelizing CPU operations</p>

<h2 id="serialization">Serialization</h2>

<h3 id="torch-save-object-file">torch.save(object, file)</h3>

<p>This function pickles a Python object to the <code class="prettyprint">file</code>. <code class="prettyprint">file</code> is either a filename or a file handle.</p>

<p><code class="prettyprint">object</code> can be a picklable python object, including <code class="prettyprint">torch</code> <code class="prettyprint">Tensor</code>s, autograd <code class="prettyprint">Variable</code>, nn <code class="prettyprint">Module</code>s etc.</p>

<p>When a group of <code class="prettyprint">torch</code> <code class="prettyprint">Tensor</code>s are saved together, and if any of them share the same storages, then this sharing is preserved during saving and loading back.</p>

<h3 id="torch-load-file">torch.load(file)</h3>

<p>This function unpickles objects that have been pickled with <code class="prettyprint">torch.save</code></p>

<h2 id="random-numbers">Random Numbers</h2>

<h3 id="torch-get_rng_state">torch.get_rng_state()</h3>

<p>Gets the current state of the torch Random Number Generator.</p>

<p>This can be passed in the future to <code class="prettyprint">torch.set_rng_state</code> to restore the current RNG state.</p>

<h3 id="torch-set_rng_state-state">torch.set_rng_state(state)</h3>

<p>Sets the current state of the torch Random Number Generator to the given <code class="prettyprint">state</code>. </p>

<h3 id="torch-manual_seed-number">torch.manual_seed(number)</h3>

<p>Sets the initial seed of the random number generator to a given number.</p>

<h3 id="torch-initial_seed">torch.initial_seed()</h3>

<p>Returns the number that is the initial seed to the Random Number Generator</p>

<h2 id="cuda">CUDA</h2>

<h3 id="torch-cuda-is_available">torch.cuda.is_available()</h3>

<p>Returns <code class="prettyprint">True</code> if CUDA is available and usable. Returns <code class="prettyprint">False</code> otherwise.</p>

<h3 id="torch-cuda-device_count">torch.cuda.device_count()</h3>

<p>Returns the number of CUDA devices on the system.</p>

<h3 id="torch-cuda-current_device">torch.cuda.current_device()</h3>

<p>Returns the device index of the current default CUDA device.</p>

<h3 id="torch-cuda-synchronize">torch.cuda.synchronize()</h3>

<p>This function issues a <code class="prettyprint">cudaDeviceSynchronize</code> on the current device, and hence waits for all in-flight CUDA computation to finish.</p>

<h3 id="torch-cuda-current_stream">torch.cuda.current_stream()</h3>

<p>Returns the handle to the current stream of the CUDA context.</p>
